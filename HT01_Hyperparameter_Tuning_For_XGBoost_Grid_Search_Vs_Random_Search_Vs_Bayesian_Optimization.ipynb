{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AAKAAASSHHH24/MACHINE_LEARNING_PRACTICALS/blob/main/HT01_Hyperparameter_Tuning_For_XGBoost_Grid_Search_Vs_Random_Search_Vs_Bayesian_Optimization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resources"
      ],
      "metadata": {
        "id": "51W6v_FC6qlq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [Blog post](https://medium.com/grabngoinfo/hyperparameter-tuning-for-xgboost-91449869c57e) for this notebook\n",
        "- Video tutorial for this post on [YouTube](https://www.youtube.com/watch?v=MeEkAYsNrgo&list=PLVppujud2yJryD5u6oPjIf2LTci3dlCJG&index=8)\n",
        "- More video tutorials on [hyperparameter tuning](https://www.youtube.com/playlist?list=PLVppujud2yJryD5u6oPjIf2LTci3dlCJG)\n",
        "- More blog posts on [hyperparameter tuning](https://medium.com/@AmyGrabNGoInfo/list/hyperparameter-tuning-2b59aca544c8)\n",
        "\n",
        "For more information about data science and machine learning, please check out my [YouTube channel](https://www.youtube.com/channel/UCmbA7XB6Wb7bLwJw9ARPcYg), [Medium Page](https://medium.com/@AmyGrabNGoInfo) and [GrabNGoInfo.com](https://grabngoinfo.com/tutorials/), or follow GrabNGoInfo on [LinkedIn](https://www.linkedin.com/company/grabngoinfo/)."
      ],
      "metadata": {
        "id": "40mCoR4u6txy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro"
      ],
      "metadata": {
        "id": "0HkdIDWj6Zn_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xEWUhuhZBMn"
      },
      "source": [
        "Grid search, random search, and Bayesian optimization are techniques for machine learning model hyperparameter tuning. This tutorial covers how to tune XGBoost hyperparameters using Python. You will learn\n",
        "* What are the differences between grid search, random search, and Bayesian optimization?\n",
        "* How to use grid search cross-validation to tune the hyperparameters for the XGBoost model?\n",
        "* How to use random search cross-validation to tune the hyperparameters for the XGBoost model?\n",
        "* How to use Bayesian optimization Hyperopt to tune the hyperparameters for the XGBoost model?\n",
        "* How to compare the results from grid search, random search, and Bayesian optimization Hyperopt?\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEbKaM3XbpYh"
      },
      "source": [
        "# Step 0: Grid Search Vs. Random Search Vs. Bayesian Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DPXdD5ZcDIO"
      },
      "source": [
        "Grid search, random search, and Bayesian optimization have the same goal of choosing the best hyperparameters for a machine learning model. But they have differences in algorithm and implementation. Understanding these differences is essential for deciding which algorithm to use.\n",
        "\n",
        "* Grid search is an exhaustive way to search hyperparameters. It evaluates every combination of hyperparameters for the model. Therefore, it can take a long time to run when there are a lot of hyperparameter combinations to compare.\n",
        "* Random search pick a fixed number of hyperparameter combinations randomly, so not every single combination is evaluated. Therefore, a more comprehensive range of values and a longer list of hyperparameters can be assessed within a given time. The downside is that sometimes the random selection may not include top performance hyperparameter combinations.\n",
        "* Bayesian optimization utilizes the results from the previous step to decide which hyperparameter combination to evaluate next. The major difference between Bayesian optimization and grid/random search is that grid search and random search consider each hyperparameter combination independently, while Bayesian optimization is dependent on the previous evaluation results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH5qFf5dxH0r"
      },
      "source": [
        "# Step 1: Install And Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-kYCFWVzSgR"
      },
      "source": [
        "In the first step, let's import the Python libraries needed for this tutorial.\n",
        "\n",
        "For this tutorial, we will need to import `datasets` to get the breast cancer dataset. `pandas` and `numpy` are for data processing. `StandardScaler'is for standardizing the dataset.\n",
        "\n",
        "`train_test_split`, `XGBClassifier` and `precision_recall_fscore_support` are for model training and performance evaluation.\n",
        "\n",
        "`GridSearchCV`, `RandomizedSearchCV`, and `hyperopt` are the hyperparameter tuning algorithms. `StratifiedKFold` and `cross_val_score` are for the cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9eq1PMeYluJ"
      },
      "source": [
        "# Dataset\n",
        "from sklearn import datasets\n",
        "\n",
        "# Data processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Standardize the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Model and performance evaluation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "# Hyperparameter tuning\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
        "from hyperopt import tpe, STATUS_OK, Trials, hp, fmin, STATUS_OK, space_eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcOT5Ex81YH4"
      },
      "source": [
        "# Step 2: Read Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BZfrfkY1eSS"
      },
      "source": [
        "In the second step, the breast cancer data from `sklearn` library is loaded and transformed into a pandas dataframe.\n",
        "\n",
        "The information summary shows that the dataset has 569 records and 31 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlB0ddhT1iOA",
        "outputId": "1752dce8-9092-4fa9-ad24-6d6b19b31309"
      },
      "source": [
        "# Load the breast cancer dataset\n",
        "data = datasets.load_breast_cancer()\n",
        "\n",
        "# Put the data in pandas dataframe format\n",
        "df = pd.DataFrame(data=data.data, columns=data.feature_names)\n",
        "df['target']=data.target\n",
        "\n",
        "# Check the data information\n",
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            " 30  target                   569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzAEdl1J1oZd"
      },
      "source": [
        "The target variable distribution shows 63% of ones and 37% of zeros in the dataset. One means the patient has breast cancer, and 0 represents the patient does not have breast cancer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZzgak8J1rqG",
        "outputId": "8d5230ad-6e21-4c61-e25d-824bbabd450c"
      },
      "source": [
        "# Check the target value distribution\n",
        "df['target'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.627417\n",
              "0    0.372583\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zte6i1eS1yUL"
      },
      "source": [
        "# Step 3: Train Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJjenHNe12M4"
      },
      "source": [
        "In step 3, we split the dataset into 80% training and 20% testing dataset. random_state makes the random split results reproducible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwPbEf6R16x0",
        "outputId": "929bd394-5c52-452f-fce4-036e136560d4"
      },
      "source": [
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df[df.columns.difference(['target'])],\n",
        "                                                    df['target'],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Check the number of records in training and testing dataset.\n",
        "print(f'The training dataset has {len(X_train)} records.')\n",
        "print(f'The testing dataset has {len(X_test)} records.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training dataset has 455 records.\n",
            "The testing dataset has 114 records.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py5RiQYO2En1"
      },
      "source": [
        "The training dataset has 455 records, and the testing dataset has 114 records."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ySY4Wok2H96"
      },
      "source": [
        "# Step 4: Standardization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFUVqqlF2SfR"
      },
      "source": [
        "Standardization is to rescale the features to the same scale. It is calculated by extracting the mean and divided by the standard deviation. After standardization, each feature has zero mean and unit standard deviation.\n",
        "\n",
        "Standardization should be fit on the training dataset only to prevent test dataset information from leaking into the training process. Then, the test dataset is standardized using the fitting results from the training dataset.\n",
        "\n",
        "There are different types of scalers. StandardScaler and MinMaxScaler are most commonly used. For a dataset with outliers, we can use RobustScaler.\n",
        "\n",
        "In this tutorial, we will use `StandardScaler`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "fvmrR2Jp2UQe",
        "outputId": "962147ca-1b6c-40a4-9fb2-64e56087c7de"
      },
      "source": [
        "# Initiate scaler\n",
        "sc = StandardScaler()\n",
        "\n",
        "# Standardize the training dataset\n",
        "X_train_transformed = pd.DataFrame(sc.fit_transform(X_train),index=X_train.index, columns=X_train.columns)\n",
        "\n",
        "# Standardized the testing dataset\n",
        "X_test_transformed = pd.DataFrame(sc.transform(X_test),index=X_test.index, columns=X_test.columns)\n",
        "\n",
        "# Summary statistics after standardization\n",
        "X_train_transformed.describe().T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         count          mean       std       min       25%  \\\n",
              "area error               455.0  6.246530e-17  1.001101 -0.705091 -0.464164   \n",
              "compactness error        455.0 -2.395154e-15  1.001101 -1.258102 -0.694353   \n",
              "concave points error     455.0  3.455112e-16  1.001101 -1.891775 -0.668493   \n",
              "concavity error          455.0  2.479091e-16  1.001101 -1.022218 -0.551340   \n",
              "fractal dimension error  455.0  5.085065e-16  1.001101 -1.050856 -0.573964   \n",
              "mean area                455.0 -2.537653e-16  1.001101 -1.365036 -0.660205   \n",
              "mean compactness         455.0  1.011157e-15  1.001101 -1.607228 -0.777087   \n",
              "mean concave points      455.0  5.817081e-16  1.001101 -1.269910 -0.734905   \n",
              "mean concavity           455.0  9.857804e-16  1.001101 -1.119899 -0.750539   \n",
              "mean fractal dimension   455.0 -3.367270e-15  1.001101 -1.776889 -0.709792   \n",
              "mean perimeter           455.0 -3.634699e-15  1.001101 -1.809497 -0.690761   \n",
              "mean radius              455.0 -1.811494e-15  1.001101 -1.819583 -0.683093   \n",
              "mean smoothness          455.0 -4.232024e-15  1.001101 -3.100011 -0.713204   \n",
              "mean symmetry            455.0 -5.910779e-15  1.001101 -2.345430 -0.701046   \n",
              "mean texture             455.0 -3.373126e-15  1.001101 -2.223500 -0.707536   \n",
              "perimeter error          455.0  7.300631e-16  1.001101 -1.015623 -0.582549   \n",
              "radius error             455.0  8.588978e-16  1.001101 -1.027104 -0.591183   \n",
              "smoothness error         455.0 -1.424990e-15  1.001101 -1.727893 -0.626524   \n",
              "symmetry error           455.0 -3.170114e-15  1.001101 -1.554767 -0.657054   \n",
              "texture error            455.0 -7.515356e-16  1.001101 -1.556840 -0.680007   \n",
              "worst area               455.0 -2.004746e-15  1.001101 -1.152259 -0.635813   \n",
              "worst compactness        455.0 -5.875642e-16  1.001101 -1.455995 -0.696132   \n",
              "worst concave points     455.0  1.093143e-16  1.001101 -1.749805 -0.770099   \n",
              "worst concavity          455.0 -5.992764e-16  1.001101 -1.312795 -0.755587   \n",
              "worst fractal dimension  455.0 -2.320000e-15  1.001101 -1.616973 -0.718962   \n",
              "worst perimeter          455.0 -8.549937e-16  1.001101 -1.578174 -0.685348   \n",
              "worst radius             455.0  1.397661e-15  1.001101 -1.572438 -0.661698   \n",
              "worst smoothness         455.0  1.198553e-15  1.001101 -2.617938 -0.743030   \n",
              "worst symmetry           455.0  5.075305e-16  1.001101 -2.124261 -0.649985   \n",
              "worst texture            455.0 -8.198570e-17  1.001101 -2.230887 -0.741229   \n",
              "\n",
              "                              50%       75%        max  \n",
              "area error              -0.325347  0.077435  10.641841  \n",
              "compactness error       -0.280607  0.358304   5.905671  \n",
              "concave points error    -0.126279  0.437566   6.504667  \n",
              "concavity error         -0.207836  0.303371  11.310294  \n",
              "fractal dimension error -0.218908  0.245340   9.345870  \n",
              "mean area               -0.289597  0.319339   5.208312  \n",
              "mean compactness        -0.241340  0.528128   3.964311  \n",
              "mean concave points     -0.391123  0.673757   4.022271  \n",
              "mean concavity          -0.344646  0.547387   4.256736  \n",
              "mean fractal dimension  -0.177285  0.464223   4.815921  \n",
              "mean perimeter          -0.242938  0.488480   3.976811  \n",
              "mean radius             -0.231498  0.459343   3.961679  \n",
              "mean smoothness         -0.080820  0.633173   4.864642  \n",
              "mean symmetry           -0.069151  0.535429   4.476124  \n",
              "mean texture            -0.118516  0.563199   4.715674  \n",
              "perimeter error         -0.276110  0.199256   9.242330  \n",
              "radius error            -0.276882  0.232400   8.736037  \n",
              "smoothness error        -0.199469  0.353671   7.906053  \n",
              "symmetry error          -0.227064  0.324207   5.008778  \n",
              "texture error           -0.198996  0.437610   6.804586  \n",
              "worst area              -0.335751  0.272486   5.955420  \n",
              "worst compactness       -0.275386  0.573857   4.424833  \n",
              "worst concave points    -0.238639  0.718999   2.709674  \n",
              "worst concavity         -0.230411  0.538350   4.672828  \n",
              "worst fractal dimension -0.213585  0.460064   4.999482  \n",
              "worst perimeter         -0.282954  0.526333   4.322305  \n",
              "worst radius            -0.263235  0.452540   4.120889  \n",
              "worst smoothness        -0.027416  0.629648   3.767506  \n",
              "worst symmetry          -0.123684  0.431944   5.917679  \n",
              "worst texture           -0.052108  0.685706   3.962127  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e97bd8a-1805-45b7-95a9-88490d3999a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>area error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>6.246530e-17</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-0.705091</td>\n",
              "      <td>-0.464164</td>\n",
              "      <td>-0.325347</td>\n",
              "      <td>0.077435</td>\n",
              "      <td>10.641841</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-2.395154e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.258102</td>\n",
              "      <td>-0.694353</td>\n",
              "      <td>-0.280607</td>\n",
              "      <td>0.358304</td>\n",
              "      <td>5.905671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>3.455112e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.891775</td>\n",
              "      <td>-0.668493</td>\n",
              "      <td>-0.126279</td>\n",
              "      <td>0.437566</td>\n",
              "      <td>6.504667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>2.479091e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.022218</td>\n",
              "      <td>-0.551340</td>\n",
              "      <td>-0.207836</td>\n",
              "      <td>0.303371</td>\n",
              "      <td>11.310294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal dimension error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>5.085065e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.050856</td>\n",
              "      <td>-0.573964</td>\n",
              "      <td>-0.218908</td>\n",
              "      <td>0.245340</td>\n",
              "      <td>9.345870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean area</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-2.537653e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.365036</td>\n",
              "      <td>-0.660205</td>\n",
              "      <td>-0.289597</td>\n",
              "      <td>0.319339</td>\n",
              "      <td>5.208312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean compactness</th>\n",
              "      <td>455.0</td>\n",
              "      <td>1.011157e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.607228</td>\n",
              "      <td>-0.777087</td>\n",
              "      <td>-0.241340</td>\n",
              "      <td>0.528128</td>\n",
              "      <td>3.964311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concave points</th>\n",
              "      <td>455.0</td>\n",
              "      <td>5.817081e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.269910</td>\n",
              "      <td>-0.734905</td>\n",
              "      <td>-0.391123</td>\n",
              "      <td>0.673757</td>\n",
              "      <td>4.022271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concavity</th>\n",
              "      <td>455.0</td>\n",
              "      <td>9.857804e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.119899</td>\n",
              "      <td>-0.750539</td>\n",
              "      <td>-0.344646</td>\n",
              "      <td>0.547387</td>\n",
              "      <td>4.256736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-3.367270e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.776889</td>\n",
              "      <td>-0.709792</td>\n",
              "      <td>-0.177285</td>\n",
              "      <td>0.464223</td>\n",
              "      <td>4.815921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean perimeter</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-3.634699e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.809497</td>\n",
              "      <td>-0.690761</td>\n",
              "      <td>-0.242938</td>\n",
              "      <td>0.488480</td>\n",
              "      <td>3.976811</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean radius</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-1.811494e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.819583</td>\n",
              "      <td>-0.683093</td>\n",
              "      <td>-0.231498</td>\n",
              "      <td>0.459343</td>\n",
              "      <td>3.961679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean smoothness</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-4.232024e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-3.100011</td>\n",
              "      <td>-0.713204</td>\n",
              "      <td>-0.080820</td>\n",
              "      <td>0.633173</td>\n",
              "      <td>4.864642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean symmetry</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-5.910779e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-2.345430</td>\n",
              "      <td>-0.701046</td>\n",
              "      <td>-0.069151</td>\n",
              "      <td>0.535429</td>\n",
              "      <td>4.476124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean texture</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-3.373126e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-2.223500</td>\n",
              "      <td>-0.707536</td>\n",
              "      <td>-0.118516</td>\n",
              "      <td>0.563199</td>\n",
              "      <td>4.715674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>7.300631e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.015623</td>\n",
              "      <td>-0.582549</td>\n",
              "      <td>-0.276110</td>\n",
              "      <td>0.199256</td>\n",
              "      <td>9.242330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>8.588978e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.027104</td>\n",
              "      <td>-0.591183</td>\n",
              "      <td>-0.276882</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>8.736037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-1.424990e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.727893</td>\n",
              "      <td>-0.626524</td>\n",
              "      <td>-0.199469</td>\n",
              "      <td>0.353671</td>\n",
              "      <td>7.906053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-3.170114e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.554767</td>\n",
              "      <td>-0.657054</td>\n",
              "      <td>-0.227064</td>\n",
              "      <td>0.324207</td>\n",
              "      <td>5.008778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-7.515356e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.556840</td>\n",
              "      <td>-0.680007</td>\n",
              "      <td>-0.198996</td>\n",
              "      <td>0.437610</td>\n",
              "      <td>6.804586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst area</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-2.004746e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.152259</td>\n",
              "      <td>-0.635813</td>\n",
              "      <td>-0.335751</td>\n",
              "      <td>0.272486</td>\n",
              "      <td>5.955420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst compactness</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-5.875642e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.455995</td>\n",
              "      <td>-0.696132</td>\n",
              "      <td>-0.275386</td>\n",
              "      <td>0.573857</td>\n",
              "      <td>4.424833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst concave points</th>\n",
              "      <td>455.0</td>\n",
              "      <td>1.093143e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.749805</td>\n",
              "      <td>-0.770099</td>\n",
              "      <td>-0.238639</td>\n",
              "      <td>0.718999</td>\n",
              "      <td>2.709674</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst concavity</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-5.992764e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.312795</td>\n",
              "      <td>-0.755587</td>\n",
              "      <td>-0.230411</td>\n",
              "      <td>0.538350</td>\n",
              "      <td>4.672828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-2.320000e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.616973</td>\n",
              "      <td>-0.718962</td>\n",
              "      <td>-0.213585</td>\n",
              "      <td>0.460064</td>\n",
              "      <td>4.999482</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst perimeter</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-8.549937e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.578174</td>\n",
              "      <td>-0.685348</td>\n",
              "      <td>-0.282954</td>\n",
              "      <td>0.526333</td>\n",
              "      <td>4.322305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst radius</th>\n",
              "      <td>455.0</td>\n",
              "      <td>1.397661e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-1.572438</td>\n",
              "      <td>-0.661698</td>\n",
              "      <td>-0.263235</td>\n",
              "      <td>0.452540</td>\n",
              "      <td>4.120889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst smoothness</th>\n",
              "      <td>455.0</td>\n",
              "      <td>1.198553e-15</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-2.617938</td>\n",
              "      <td>-0.743030</td>\n",
              "      <td>-0.027416</td>\n",
              "      <td>0.629648</td>\n",
              "      <td>3.767506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst symmetry</th>\n",
              "      <td>455.0</td>\n",
              "      <td>5.075305e-16</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-2.124261</td>\n",
              "      <td>-0.649985</td>\n",
              "      <td>-0.123684</td>\n",
              "      <td>0.431944</td>\n",
              "      <td>5.917679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst texture</th>\n",
              "      <td>455.0</td>\n",
              "      <td>-8.198570e-17</td>\n",
              "      <td>1.001101</td>\n",
              "      <td>-2.230887</td>\n",
              "      <td>-0.741229</td>\n",
              "      <td>-0.052108</td>\n",
              "      <td>0.685706</td>\n",
              "      <td>3.962127</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e97bd8a-1805-45b7-95a9-88490d3999a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e97bd8a-1805-45b7-95a9-88490d3999a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e97bd8a-1805-45b7-95a9-88490d3999a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GeeE0D42cOu"
      },
      "source": [
        "We can see that after using StandardScaler, all the features have zero mean and unit standard deviation.\n",
        "\n",
        "Let's get the summary statistics for the training data before standardization as well, and we can see that the mean and standard deviation can be very different in scale. For example, the area error has a mean value of 40 and a standard deviation of 47. On the other hand, the compactness error has a mean of about 0.023 and a standard deviation of 0.019."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "AxgMHlKG2esM",
        "outputId": "c07a4dc0-cdd7-4ede-8c41-0c31fe36ade6"
      },
      "source": [
        "# Summary statistics before standardization\n",
        "X_train.describe().T"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         count        mean         std         min  \\\n",
              "area error               455.0   40.071299   47.236319    6.802000   \n",
              "compactness error        455.0    0.025635    0.018607    0.002252   \n",
              "concave points error     455.0    0.011894    0.006294    0.000000   \n",
              "concavity error          455.0    0.032824    0.032146    0.000000   \n",
              "fractal dimension error  455.0    0.003820    0.002787    0.000895   \n",
              "mean area                455.0  654.377582  354.943187  170.400000   \n",
              "mean compactness         455.0    0.103619    0.052470    0.019380   \n",
              "mean concave points      455.0    0.048280    0.038060    0.000000   \n",
              "mean concavity           455.0    0.088898    0.079468    0.000000   \n",
              "mean fractal dimension   455.0    0.062757    0.007210    0.049960   \n",
              "mean perimeter           455.0   91.882242   24.322027   47.920000   \n",
              "mean radius              455.0   14.117635    3.535815    7.691000   \n",
              "mean smoothness          455.0    0.095744    0.013923    0.052630   \n",
              "mean symmetry            455.0    0.181099    0.027487    0.116700   \n",
              "mean texture             455.0   19.185033    4.266005    9.710000   \n",
              "perimeter error          455.0    2.858253    2.071209    0.757000   \n",
              "radius error             455.0    0.402016    0.283161    0.111500   \n",
              "smoothness error         455.0    0.006989    0.003057    0.001713   \n",
              "symmetry error           455.0    0.020574    0.008172    0.007882   \n",
              "texture error            455.0    1.202687    0.541747    0.360200   \n",
              "worst area               455.0  876.987033  567.672841  223.600000   \n",
              "worst compactness        455.0    0.252742    0.155014    0.027290   \n",
              "worst concave points     455.0    0.114182    0.065326    0.000000   \n",
              "worst concavity          455.0    0.274595    0.209398    0.000000   \n",
              "worst fractal dimension  455.0    0.083868    0.017848    0.055040   \n",
              "worst perimeter          455.0  107.103121   33.374664   54.490000   \n",
              "worst radius             455.0   16.235103    4.811267    8.678000   \n",
              "worst smoothness         455.0    0.131532    0.023083    0.071170   \n",
              "worst symmetry           455.0    0.290502    0.063151    0.156500   \n",
              "worst texture            455.0   25.535692    6.065108   12.020000   \n",
              "\n",
              "                                25%         50%          75%         max  \n",
              "area error                18.170000   24.720000    43.725000   542.20000  \n",
              "compactness error          0.012730    0.020420     0.032295     0.13540  \n",
              "concave points error       0.007691    0.011100     0.014645     0.05279  \n",
              "concavity error            0.015120    0.026150     0.042565     0.39600  \n",
              "fractal dimension error    0.002222    0.003211     0.004504     0.02984  \n",
              "mean area                420.300000  551.700000   767.600000  2501.00000  \n",
              "mean compactness           0.062890    0.090970     0.131300     0.31140  \n",
              "mean concave points        0.020340    0.033410     0.073895     0.20120  \n",
              "mean concavity             0.029320    0.061540     0.132350     0.42680  \n",
              "mean fractal dimension     0.057645    0.061480     0.066100     0.09744  \n",
              "mean perimeter            75.100000   85.980000   103.750000   188.50000  \n",
              "mean radius               11.705000   13.300000    15.740000    28.11000  \n",
              "mean smoothness            0.085825    0.094620     0.104550     0.16340  \n",
              "mean symmetry              0.161850    0.179200     0.195800     0.30400  \n",
              "mean texture              16.170000   18.680000    21.585000    39.28000  \n",
              "perimeter error            1.653000    2.287000     3.270500    21.98000  \n",
              "radius error               0.234800    0.323700     0.467750     2.87300  \n",
              "smoothness error           0.005076    0.006380     0.008069     0.03113  \n",
              "symmetry error             0.015210    0.018720     0.023220     0.06146  \n",
              "texture error              0.834700    1.095000     1.439500     4.88500  \n",
              "worst area               516.450000  686.600000  1031.500000  4254.00000  \n",
              "worst compactness          0.144950    0.210100     0.341600     0.93790  \n",
              "worst concave points       0.063930    0.098610     0.161100     0.29100  \n",
              "worst concavity            0.116550    0.226400     0.387200     1.25200  \n",
              "worst fractal dimension    0.071050    0.080060     0.092070     0.17300  \n",
              "worst perimeter           84.255000   97.670000   124.650000   251.20000  \n",
              "worst radius              13.055000   14.970000    18.410000    36.04000  \n",
              "worst smoothness           0.114400    0.130900     0.146050     0.21840  \n",
              "worst symmetry             0.249500    0.282700     0.317750     0.66380  \n",
              "worst texture             21.045000   25.220000    29.690000    49.54000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9ba50b9-c722-4c57-a12e-05ece4b63f20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>area error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>40.071299</td>\n",
              "      <td>47.236319</td>\n",
              "      <td>6.802000</td>\n",
              "      <td>18.170000</td>\n",
              "      <td>24.720000</td>\n",
              "      <td>43.725000</td>\n",
              "      <td>542.20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.025635</td>\n",
              "      <td>0.018607</td>\n",
              "      <td>0.002252</td>\n",
              "      <td>0.012730</td>\n",
              "      <td>0.020420</td>\n",
              "      <td>0.032295</td>\n",
              "      <td>0.13540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concave points error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.011894</td>\n",
              "      <td>0.006294</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007691</td>\n",
              "      <td>0.011100</td>\n",
              "      <td>0.014645</td>\n",
              "      <td>0.05279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>concavity error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.032824</td>\n",
              "      <td>0.032146</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015120</td>\n",
              "      <td>0.026150</td>\n",
              "      <td>0.042565</td>\n",
              "      <td>0.39600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fractal dimension error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.003820</td>\n",
              "      <td>0.002787</td>\n",
              "      <td>0.000895</td>\n",
              "      <td>0.002222</td>\n",
              "      <td>0.003211</td>\n",
              "      <td>0.004504</td>\n",
              "      <td>0.02984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean area</th>\n",
              "      <td>455.0</td>\n",
              "      <td>654.377582</td>\n",
              "      <td>354.943187</td>\n",
              "      <td>170.400000</td>\n",
              "      <td>420.300000</td>\n",
              "      <td>551.700000</td>\n",
              "      <td>767.600000</td>\n",
              "      <td>2501.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean compactness</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.103619</td>\n",
              "      <td>0.052470</td>\n",
              "      <td>0.019380</td>\n",
              "      <td>0.062890</td>\n",
              "      <td>0.090970</td>\n",
              "      <td>0.131300</td>\n",
              "      <td>0.31140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concave points</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.048280</td>\n",
              "      <td>0.038060</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020340</td>\n",
              "      <td>0.033410</td>\n",
              "      <td>0.073895</td>\n",
              "      <td>0.20120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean concavity</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.088898</td>\n",
              "      <td>0.079468</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.029320</td>\n",
              "      <td>0.061540</td>\n",
              "      <td>0.132350</td>\n",
              "      <td>0.42680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.062757</td>\n",
              "      <td>0.007210</td>\n",
              "      <td>0.049960</td>\n",
              "      <td>0.057645</td>\n",
              "      <td>0.061480</td>\n",
              "      <td>0.066100</td>\n",
              "      <td>0.09744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean perimeter</th>\n",
              "      <td>455.0</td>\n",
              "      <td>91.882242</td>\n",
              "      <td>24.322027</td>\n",
              "      <td>47.920000</td>\n",
              "      <td>75.100000</td>\n",
              "      <td>85.980000</td>\n",
              "      <td>103.750000</td>\n",
              "      <td>188.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean radius</th>\n",
              "      <td>455.0</td>\n",
              "      <td>14.117635</td>\n",
              "      <td>3.535815</td>\n",
              "      <td>7.691000</td>\n",
              "      <td>11.705000</td>\n",
              "      <td>13.300000</td>\n",
              "      <td>15.740000</td>\n",
              "      <td>28.11000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean smoothness</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.095744</td>\n",
              "      <td>0.013923</td>\n",
              "      <td>0.052630</td>\n",
              "      <td>0.085825</td>\n",
              "      <td>0.094620</td>\n",
              "      <td>0.104550</td>\n",
              "      <td>0.16340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean symmetry</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.181099</td>\n",
              "      <td>0.027487</td>\n",
              "      <td>0.116700</td>\n",
              "      <td>0.161850</td>\n",
              "      <td>0.179200</td>\n",
              "      <td>0.195800</td>\n",
              "      <td>0.30400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean texture</th>\n",
              "      <td>455.0</td>\n",
              "      <td>19.185033</td>\n",
              "      <td>4.266005</td>\n",
              "      <td>9.710000</td>\n",
              "      <td>16.170000</td>\n",
              "      <td>18.680000</td>\n",
              "      <td>21.585000</td>\n",
              "      <td>39.28000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>2.858253</td>\n",
              "      <td>2.071209</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>1.653000</td>\n",
              "      <td>2.287000</td>\n",
              "      <td>3.270500</td>\n",
              "      <td>21.98000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>radius error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.402016</td>\n",
              "      <td>0.283161</td>\n",
              "      <td>0.111500</td>\n",
              "      <td>0.234800</td>\n",
              "      <td>0.323700</td>\n",
              "      <td>0.467750</td>\n",
              "      <td>2.87300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>smoothness error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.006989</td>\n",
              "      <td>0.003057</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.005076</td>\n",
              "      <td>0.006380</td>\n",
              "      <td>0.008069</td>\n",
              "      <td>0.03113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>symmetry error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.020574</td>\n",
              "      <td>0.008172</td>\n",
              "      <td>0.007882</td>\n",
              "      <td>0.015210</td>\n",
              "      <td>0.018720</td>\n",
              "      <td>0.023220</td>\n",
              "      <td>0.06146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>texture error</th>\n",
              "      <td>455.0</td>\n",
              "      <td>1.202687</td>\n",
              "      <td>0.541747</td>\n",
              "      <td>0.360200</td>\n",
              "      <td>0.834700</td>\n",
              "      <td>1.095000</td>\n",
              "      <td>1.439500</td>\n",
              "      <td>4.88500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst area</th>\n",
              "      <td>455.0</td>\n",
              "      <td>876.987033</td>\n",
              "      <td>567.672841</td>\n",
              "      <td>223.600000</td>\n",
              "      <td>516.450000</td>\n",
              "      <td>686.600000</td>\n",
              "      <td>1031.500000</td>\n",
              "      <td>4254.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst compactness</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.252742</td>\n",
              "      <td>0.155014</td>\n",
              "      <td>0.027290</td>\n",
              "      <td>0.144950</td>\n",
              "      <td>0.210100</td>\n",
              "      <td>0.341600</td>\n",
              "      <td>0.93790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst concave points</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.114182</td>\n",
              "      <td>0.065326</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.063930</td>\n",
              "      <td>0.098610</td>\n",
              "      <td>0.161100</td>\n",
              "      <td>0.29100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst concavity</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.274595</td>\n",
              "      <td>0.209398</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.116550</td>\n",
              "      <td>0.226400</td>\n",
              "      <td>0.387200</td>\n",
              "      <td>1.25200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.083868</td>\n",
              "      <td>0.017848</td>\n",
              "      <td>0.055040</td>\n",
              "      <td>0.071050</td>\n",
              "      <td>0.080060</td>\n",
              "      <td>0.092070</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst perimeter</th>\n",
              "      <td>455.0</td>\n",
              "      <td>107.103121</td>\n",
              "      <td>33.374664</td>\n",
              "      <td>54.490000</td>\n",
              "      <td>84.255000</td>\n",
              "      <td>97.670000</td>\n",
              "      <td>124.650000</td>\n",
              "      <td>251.20000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst radius</th>\n",
              "      <td>455.0</td>\n",
              "      <td>16.235103</td>\n",
              "      <td>4.811267</td>\n",
              "      <td>8.678000</td>\n",
              "      <td>13.055000</td>\n",
              "      <td>14.970000</td>\n",
              "      <td>18.410000</td>\n",
              "      <td>36.04000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst smoothness</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.131532</td>\n",
              "      <td>0.023083</td>\n",
              "      <td>0.071170</td>\n",
              "      <td>0.114400</td>\n",
              "      <td>0.130900</td>\n",
              "      <td>0.146050</td>\n",
              "      <td>0.21840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst symmetry</th>\n",
              "      <td>455.0</td>\n",
              "      <td>0.290502</td>\n",
              "      <td>0.063151</td>\n",
              "      <td>0.156500</td>\n",
              "      <td>0.249500</td>\n",
              "      <td>0.282700</td>\n",
              "      <td>0.317750</td>\n",
              "      <td>0.66380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>worst texture</th>\n",
              "      <td>455.0</td>\n",
              "      <td>25.535692</td>\n",
              "      <td>6.065108</td>\n",
              "      <td>12.020000</td>\n",
              "      <td>21.045000</td>\n",
              "      <td>25.220000</td>\n",
              "      <td>29.690000</td>\n",
              "      <td>49.54000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9ba50b9-c722-4c57-a12e-05ece4b63f20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9ba50b9-c722-4c57-a12e-05ece4b63f20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9ba50b9-c722-4c57-a12e-05ece4b63f20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdcA-f-329ol"
      },
      "source": [
        "# Step 5: XGBoost Classifier With No Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjMdODxM3Tyf"
      },
      "source": [
        "In step 5, we will create an XGBoost classification model with default hyperparameters. This serves as a baseline model to compare against.\n",
        "\n",
        "This is a list of the hyperparameters we can tune. Usually, a subset of essential hyperparameters will be tuned.\n",
        "\n",
        "* `base_score` is the starting prediction score for all the instances at the model initiation. This number does not have much impact on the final results when there is a sufficient number of iterations. Therefore, `base_score` is not a good choice for hyperparameter tuning.\n",
        "* `booster` specifies which booster to use for the model. Booster `gbtree` and `dart` use tree-based models, and booster `gblinear` uses linear functions.\n",
        "* `colsample_bylevel` is the subsample ratio of columns for each depth level from the set of columns for the current tree.\n",
        "* `colsample_bynode` is the subsample ratio of columns for each node(split) from the set of columns for the current level.\n",
        "* `colsample_bytree` is the subsample ratio of columns for each tree from the set of all columns in the training dataset.\n",
        "* `gamma` is a value greater than or equal to zero. It is the minimum loss reduction required for a split.\n",
        "* `learning_rate` is also called `eta`. It is a value between 0 and 1. It is the step size shrinkage for the feature weights to make the boosting process more conservative.\n",
        "* `max_delta_step` puts an absolute regularization weight capping before applying `eta` correction. The default value of 0 means that there is no restriction on the maximum value of the weight. A positive number might help for the dataset with highly imbalanced classes. A value between 1 to 10 is usually used but it can take any value greater than or equal to 0.\n",
        "* `max_depth` is the maximum depth of a tree and it can take the value of any integer greater than or equal to 0. 0 means no limit to the tree depth. A larger value for `max_depth` builds more complex models and tends to overfit.\n",
        "* `min_child_weight` is the minimum sum of instance weight needed in a child for partitioning. It takes the value greater than or equal to 0.\n",
        "* `missing` is the value in the input data that needs to be considered as a missing value. The default value is `None`, meaning that only `np.nan` is considered to be missing values.\n",
        "* `n_estimators` is the number of gradient boosted trees.\n",
        "* `n_jobs` takes in the number of parallel threads for the model. `n_jobs=-1` means using all the available cores for parallel processing.\n",
        "* `nthread` is the number of parallel threads for running XGBoost.\n",
        "*  `'objective': 'binary:logistic'` means that the logistic regression for binary classification is used as the learning objective and the model output probability.\n",
        "* `random_state` sets a seed for model reproducibility.\n",
        "* `reg_alpha` provides L1 regularization to the weight. Higher values result in more conservative models. The default value of 0 means no L1 regularization.\n",
        "* `reg_lambda` provides L2 regularization to the weight. Higher values result in more conservative models. XGBoost applies L2 regularization by default.\n",
        "* `scale_pos_weight` controls the balance of positive and negative weights. It's useful for unbalanced classes.\n",
        "* `seed` sets a random number seed.\n",
        "* `silent` decides whether to print out information during model training.\n",
        "* `subsample` is the percentage of randomly sampled training data before growing trees. It happens in every boosting iteration. It is greater than 0 and less than or equal to 1. The default value of 1 means all the data in the training dataset will be used to build trees. A value of less than 1 helps to prevent overfitting.\n",
        "* `verbosity` controls how many messages are printed. The valid values are 0 (silent), 1 (warning), 2 (info), and 3 (debug)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ni9aL9JJ3q9R",
        "outputId": "8b4cfcea-bf31-446d-db78-01f431b4280c"
      },
      "source": [
        "# Initiate XGBoost Classifier\n",
        "xgboost = XGBClassifier()\n",
        "\n",
        "# Print default setting\n",
        "xgboost.get_params()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'base_score': 0.5,\n",
              " 'booster': 'gbtree',\n",
              " 'colsample_bylevel': 1,\n",
              " 'colsample_bynode': 1,\n",
              " 'colsample_bytree': 1,\n",
              " 'gamma': 0,\n",
              " 'learning_rate': 0.1,\n",
              " 'max_delta_step': 0,\n",
              " 'max_depth': 3,\n",
              " 'min_child_weight': 1,\n",
              " 'missing': None,\n",
              " 'n_estimators': 100,\n",
              " 'n_jobs': 1,\n",
              " 'nthread': None,\n",
              " 'objective': 'binary:logistic',\n",
              " 'random_state': 0,\n",
              " 'reg_alpha': 0,\n",
              " 'reg_lambda': 1,\n",
              " 'scale_pos_weight': 1,\n",
              " 'seed': None,\n",
              " 'silent': None,\n",
              " 'subsample': 1,\n",
              " 'verbosity': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5EAukAd62D_"
      },
      "source": [
        "When training the model, `seed=0` makes sure that we get reproducible results. After running the baseline XGBoost model, we predicted the testing dataset using `.predict` and calculated the predicted probabilities using `.predict_proba`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcVU8Qwv5dV9"
      },
      "source": [
        "# Train the model\n",
        "xgboost = XGBClassifier(seed=0).fit(X_train_transformed,y_train)\n",
        "\n",
        "# Make prediction\n",
        "xgboost_predict = xgboost.predict(X_test_transformed)\n",
        "\n",
        "# Get predicted probability\n",
        "xgboost_predict_prob = xgboost.predict_proba(X_test_transformed)[:,1]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlORXsAN75A-"
      },
      "source": [
        "We want to capture as many actual cancer patients as possible for this particular dataset, so we will use recall as the performance metric to optimize."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BUHAnMv8jSE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334ad09f-3751-4317-ddcc-0f3fb69e1d62"
      },
      "source": [
        "# Get performance metrics\n",
        "precision, recall, fscore, support = score(y_test, xgboost_predict)\n",
        "\n",
        "# Print result\n",
        "print(f'The recall value for the baseline xgboost model is {recall[1]:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recall value for the baseline xgboost model is 0.9718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myrLct1SzVD1"
      },
      "source": [
        "The baseline XGBoost model gave us a recall of 97.18%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmx75QzGCpaT"
      },
      "source": [
        "# Step 6: Grid Search for XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6knXVfAdC07_"
      },
      "source": [
        "In step 6, we will use grid search to find the best hyperparameter combinations for the XGBoost model. Grid search is an exhaustive hyperparameter search method. It trains models for every combination of specified hyperparameter values. Therefore, it can take a long time to run if we test out more hyperparameters and values.\n",
        "\n",
        "For this reason, we would like to have the grid search space relatively small so the process can finish in a reasonable timeframe. The search space includes the hyperparameters, and their values grid search builds models for. We had three hyperparameters for grid search in this example.\n",
        "\n",
        "* `colsample_bytree` is the percentage of columns to be randomly sampled for each tree.\n",
        "* `reg_alpha` provides l1 regularization to the weight. Higher values result in more conservative models.\n",
        "* `reg_lambda` provides l2 regularization to the weight. Higher values result in more conservative models.\n",
        "\n",
        "Scoring is the metric to evaluate the cross-validation results for each model. Since recall is the evaluation metric for the model, we set `scoring = ['recall']`. The scoring option can take more than one metric in the list.\n",
        "\n",
        "`StratifiedKFold` is used for the cross-validation. It helps us keep the class ratio in the folds the same as the training dataset. `n_splits=3` means we are doing 3-fold cross-validation. `shuffle=True` means the data are shuffled before splitting. `random_state=0` makes the shuffle reproducible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkU1do8QGusB"
      },
      "source": [
        "# Define the search space\n",
        "param_grid = {\n",
        "    # Percentage of columns to be randomly samples for each tree.\n",
        "    \"colsample_bytree\": [ 0.3, 0.5 , 0.8 ],\n",
        "    # reg_alpha provides l1 regularization to the weight, higher values result in more conservative models\n",
        "    \"reg_alpha\": [0, 0.5, 1, 5],\n",
        "    # reg_lambda provides l2 regularization to the weight, higher values result in more conservative models\n",
        "    \"reg_lambda\": [0, 0.5, 1, 5]\n",
        "    }\n",
        "\n",
        "# Set up score\n",
        "scoring = ['recall']\n",
        "\n",
        "# Set up the k-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZUjDOtsXSXM"
      },
      "source": [
        "We specified a few options for `GridSearchCV`.\n",
        "* `estimator=xgboost` means we are using XGBoost as the model.\n",
        "* `param_grid=param_grid` takes our pre-defined search space for the grid search.\n",
        "* `scoring=scoring` set the performance evaluation metric. Because we set the scoring to 'recall', the model will use recall as the evaluation metric.\n",
        "* `refit='recall'` enables refitting the model with the best parameters on the whole training dataset.\n",
        "* `n_jobs=-1` means parallel processing using all the processors.\n",
        "* `cv=kfold` takes the `StratifiedKFold` we defined.\n",
        "* `verbose` controls the number of messages returned by the grid search. The higher the number, the more information is returned. `verbose=0` means silent output.\n",
        "\n",
        "After fitting `GridSearchCV` on the training dataset, we will have 48 hyperparameter combinations. Since 3-fold cross-validation is used, there are 144 models trained in total.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jug6BP8RKW11",
        "outputId": "eea13ce7-59be-40f3-eeb2-829957ac0ce8"
      },
      "source": [
        "# Define grid search\n",
        "grid_search = GridSearchCV(estimator=xgboost,\n",
        "                           param_grid=param_grid,\n",
        "                           scoring=scoring,\n",
        "                           refit='recall',\n",
        "                           n_jobs=-1,\n",
        "                           cv=kfold,\n",
        "                           verbose=0)\n",
        "\n",
        "# Fit grid search\n",
        "grid_result = grid_search.fit(X_train_transformed, y_train)\n",
        "\n",
        "# Print grid search summary\n",
        "grid_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=0, shuffle=True),\n",
              "             error_score=nan,\n",
              "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                     colsample_bylevel=1, colsample_bynode=1,\n",
              "                                     colsample_bytree=1, gamma=0,\n",
              "                                     learning_rate=0.1, max_delta_step=0,\n",
              "                                     max_depth=3, min_child_weight=1,\n",
              "                                     missing=None, n_estimators=100, n_jobs=1,\n",
              "                                     nthread=None, objective='binary:logistic',\n",
              "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
              "                                     scale_pos_weight=1, seed=0, silent=None,\n",
              "                                     subsample=1, verbosity=1),\n",
              "             iid='deprecated', n_jobs=-1,\n",
              "             param_grid={'colsample_bytree': [0.3, 0.5, 0.8],\n",
              "                         'reg_alpha': [0, 0.5, 1, 5],\n",
              "                         'reg_lambda': [0, 0.5, 1, 5]},\n",
              "             pre_dispatch='2*n_jobs', refit='recall', return_train_score=False,\n",
              "             scoring=['recall'], verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBEaK_kjyEWP",
        "outputId": "5e5b0602-31e3-4b15-c703-2e1102cf8cbe"
      },
      "source": [
        "# Print the best score and the corresponding hyperparameters\n",
        "print(f'The best score is {grid_result.best_score_:.4f}')\n",
        "print('The best score standard deviation is', round(grid_result.cv_results_['std_test_recall'][grid_result.best_index_], 4))\n",
        "print(f'The best hyperparameters are {grid_result.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best score is 0.9895\n",
            "The best score standard deviation is 0.0086\n",
            "The best hyperparameters are {'colsample_bytree': 0.8, 'reg_alpha': 0.5, 'reg_lambda': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfOwK1kjnS5V"
      },
      "source": [
        "The grid search cross-validation results show that 80% of features, using l1 regularization with 0.5 penalty coefficient and no l2 regularization gave us the best results. The best recall is 98.95%, and the standard deviation of the score is 0.86%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RfqDycb1Fv-",
        "outputId": "f94a9ae0-1a47-486c-ecd1-8b4f4cddaf49"
      },
      "source": [
        "# Make prediction using the best model\n",
        "grid_predict = grid_search.predict(X_test_transformed)\n",
        "\n",
        "# Get predicted probabilities\n",
        "grid_predict_prob = grid_search.predict_proba(X_test_transformed)[:,1]\n",
        "\n",
        "# Get performance metrics\n",
        "precision, recall, fscore, support = score(y_test, grid_predict)\n",
        "\n",
        "# Print result\n",
        "print(f'The recall value for the xgboost grid search is {recall[1]:.4f}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recall value for the xgboost grid search is 0.9718\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOPxPyYd44Xl"
      },
      "source": [
        "We can see that the grid search recall value is the same as the baseline XGBoost model at 97.18%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Jhaw8JtwFpH"
      },
      "source": [
        "# Step 7: Random Search for XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVpslGbI-KRS"
      },
      "source": [
        "In step 7, we are using a random search for XGBoost hyperparameter tuning. Since random search randomly picks a fixed number of hyperparameter combinations, we can afford to try more hyperparameters and more values. Therefore, we added three more parameters to the search space.\n",
        "\n",
        "* `learning_rate` shrinks the weights to make the boosting process more conservative.\n",
        "* `max_depth` is the maximum depth of the tree. Increasing it increases the model complexity.\n",
        "* `gamma` specifies the minimum loss reduction required to do a split.\n",
        "\n",
        "If at least one of the parameters is a distribution, sampling with replacement is used for a random search. If all parameters are provided as a list, sampling without replacement is used. Each list is treated as a uniform distribution.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wgDHDDd7FtS"
      },
      "source": [
        "# Define the search space\n",
        "param_grid = {\n",
        "    # Learning rate shrinks the weights to make the boosting process more conservative\n",
        "    \"learning_rate\": [0.0001,0.001, 0.01, 0.1, 1] ,\n",
        "    # Maximum depth of the tree, increasing it increases the model complexity.\n",
        "    \"max_depth\": range(3,21,3),\n",
        "    # Gamma specifies the minimum loss reduction required to make a split.\n",
        "    \"gamma\": [i/10.0 for i in range(0,5)],\n",
        "    # Percentage of columns to be randomly samples for each tree.\n",
        "    \"colsample_bytree\": [i/10.0 for i in range(3,10)],\n",
        "    # reg_alpha provides l1 regularization to the weight, higher values result in more conservative models\n",
        "    \"reg_alpha\": [1e-5, 1e-2, 0.1, 1, 10, 100],\n",
        "    # reg_lambda provides l2 regularization to the weight, higher values result in more conservative models\n",
        "    \"reg_lambda\": [1e-5, 1e-2, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Set up score\n",
        "scoring = ['recall']\n",
        "\n",
        "# Set up the k-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UjcxCzqcaiY"
      },
      "source": [
        "The same scoring metric and cross-validation values used in grid search are used for the random search. But for a random search, we need to specify a value for `n_iter`, the number of parameter combinations sampled. So we are randomly testing 48 combinations for this example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0uR9dh2CDe9",
        "outputId": "d690ff3d-8992-4079-8e49-b4c9d37a0bda"
      },
      "source": [
        "# Define random search\n",
        "random_search = RandomizedSearchCV(estimator=xgboost,\n",
        "                           param_distributions=param_grid,\n",
        "                           n_iter=48,\n",
        "                           scoring=scoring,\n",
        "                           refit='recall',\n",
        "                           n_jobs=-1,\n",
        "                           cv=kfold,\n",
        "                           verbose=0)\n",
        "\n",
        "# Fit grid search\n",
        "random_result = random_search.fit(X_train_transformed, y_train)\n",
        "\n",
        "# Print grid search summary\n",
        "random_result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=0, shuffle=True),\n",
              "                   error_score=nan,\n",
              "                   estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                                           colsample_bylevel=1,\n",
              "                                           colsample_bynode=1,\n",
              "                                           colsample_bytree=1, gamma=0,\n",
              "                                           learning_rate=0.1, max_delta_step=0,\n",
              "                                           max_depth=3, min_child_weight=1,\n",
              "                                           missing=None, n_estimators=100,\n",
              "                                           n_jobs=1, nthread=None,\n",
              "                                           objective='binar...\n",
              "                   param_distributions={'colsample_bytree': [0.3, 0.4, 0.5, 0.6,\n",
              "                                                             0.7, 0.8, 0.9],\n",
              "                                        'gamma': [0.0, 0.1, 0.2, 0.3, 0.4],\n",
              "                                        'learning_rate': [0.0001, 0.001, 0.01,\n",
              "                                                          0.1, 1],\n",
              "                                        'max_depth': range(3, 21, 3),\n",
              "                                        'reg_alpha': [1e-05, 0.01, 0.1, 1, 10,\n",
              "                                                      100],\n",
              "                                        'reg_lambda': [1e-05, 0.01, 0.1, 1, 10,\n",
              "                                                       100]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit='recall',\n",
              "                   return_train_score=False, scoring=['recall'], verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8dcuHpUDgqb",
        "outputId": "17f5b491-98ba-4355-aa43-a4d5e92e896e"
      },
      "source": [
        "# Print the best score and the corresponding hyperparameters\n",
        "print(f'The best score is {random_result.best_score_:.4f}')\n",
        "print('The best score standard deviation is', round(random_result.cv_results_['std_test_recall'][random_result.best_index_], 4))\n",
        "print(f'The best hyperparameters are {random_result.best_params_}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The best score is 0.9895\n",
            "The best score standard deviation is 0.0086\n",
            "The best hyperparameters are {'reg_lambda': 1e-05, 'reg_alpha': 1e-05, 'max_depth': 6, 'learning_rate': 0.1, 'gamma': 0.1, 'colsample_bytree': 0.5}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUpq3XmTlWqw"
      },
      "source": [
        "After finishing the random search cross-validation, we printed out the best score, standard deviation, and the best parameters. Although the best parameters are different from the grid search, the best score and standard deviation for the cross-validation are very close."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_83I8O3fDrFL",
        "outputId": "d386c618-770e-48b7-cae4-5015e637171c"
      },
      "source": [
        "# Make prediction using the best model\n",
        "random_predict = random_search.predict(X_test_transformed)\n",
        "\n",
        "# Get predicted probabilities\n",
        "random_predict_prob = random_search.predict_proba(X_test_transformed)[:,1]\n",
        "\n",
        "# Get performance metrics\n",
        "precision, recall, fscore, support = score(y_test, random_predict)\n",
        "\n",
        "# Print result\n",
        "print(f'The recall value for the xgboost random search is {recall[1]:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recall value for the xgboost random search is 0.9859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMAJW-LwjbkM"
      },
      "source": [
        "The random search recall value on the test dataset is creased from 97.18% to 98.59%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDnzPbvUD7Hm"
      },
      "source": [
        "# Step 8: Bayesian Optimization For XGBoost"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In step 8, we will apply Hyperopt Bayesian optimization on XGBoost hyperparameter tuning. According to the documentation on [Hyperopt github](https://github.com/hyperopt/hyperopt/wiki/FMin) page, there are four key elements for Hyperopt:\n",
        "* the space over which to search\n",
        "* the objective function to minimize\n",
        "* the database in which to store all the point evaluations of the search\n",
        "* the search algorithm to use\n",
        "\n",
        "For the search space, the same space as the random search is used for the Hyperopt Bayesian optimization."
      ],
      "metadata": {
        "id": "38S9OcoRpOea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Space\n",
        "space = {\n",
        "    'learning_rate': hp.choice('learning_rate', [0.0001,0.001, 0.01, 0.1, 1]),\n",
        "    'max_depth' : hp.choice('max_depth', range(3,21,3)),\n",
        "    'gamma' : hp.choice('gamma', [i/10.0 for i in range(0,5)]),\n",
        "    'colsample_bytree' : hp.choice('colsample_bytree', [i/10.0 for i in range(3,10)]),\n",
        "    'reg_alpha' : hp.choice('reg_alpha', [1e-5, 1e-2, 0.1, 1, 10, 100]),\n",
        "    'reg_lambda' : hp.choice('reg_lambda', [1e-5, 1e-2, 0.1, 1, 10, 100])\n",
        "}"
      ],
      "metadata": {
        "id": "V20VvreOpQfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`StratifiedKFold` is used to split the training dataset into k folds and keep the ratio between the classes in each fold the same as the training dataset. It is used for the cross-validation.\n",
        "  * `n_splits=3` means that the training dataset is split into 3 folds. This is because our dataset is small. For a larger dataset, usually 5 or 10 folds are used.\n",
        "  * `shuffle=True` means that the dataset will be shuffled before splitting into folds. Note that the samples within each split will not be shuffled.\n",
        "  * `random_state=0` make the split reproducible."
      ],
      "metadata": {
        "id": "WGXS84Uspaap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the k-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=0)"
      ],
      "metadata": {
        "id": "eiFkvdIopdib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then an objective function is defined.\n",
        " * `XGBClassifier` is used as the model algorithm. `seed=0` makes the model results reproducible. `**params` takes in the hyperparameter values.\n",
        " * `cross_val_score` produces k scores, one for each of the k folds. We get the mean of the k scores and output the average value.\n",
        "  * `estimator` takes the estimator to fit the data.\n",
        "  * `X` takes the training dataset feature matrix and `y` takes the target variable for the training dataset.\n",
        "  * `cv` determines the cross-validation splitting strategy. We set `cv=kfold`, which is the output from the `StratifiedKFold`.\n",
        "  * `scoring='recall'` means that `recall` is the key metric for the model.\n",
        "  * `n_jobs=-1` enables parallel model training.\n",
        " * Next, `loss` is defined. Because the model's goal is to maximize recall, it is the same as minimizing negative recall, so we set `loss = - score`.\n",
        " * The function returns a dictionary with `loss`, `params`, and `status`."
      ],
      "metadata": {
        "id": "VtM5ziZiph5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Objective function\n",
        "def objective(params):\n",
        "\n",
        "    xgboost = XGBClassifier(seed=0, **params)\n",
        "    score = cross_val_score(estimator=xgboost,\n",
        "                            X=X_train_transformed,\n",
        "                            y=y_train,\n",
        "                            cv=kfold,\n",
        "                            scoring='recall',\n",
        "                            n_jobs=-1).mean()\n",
        "\n",
        "    # Loss is negative score\n",
        "    loss = - score\n",
        "\n",
        "    # Dictionary with information for evaluation\n",
        "    return {'loss': loss, 'params': params, 'status': STATUS_OK}"
      ],
      "metadata": {
        "id": "3EeChF3jqN4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`fmin` is the function to search the best hyperparameters with the smallest loss value.\n",
        "* `fn` takes in the objective function.\n",
        "* `space` is for the search space of the hyperparameters.\n",
        "* `algo` is for the type of search algorithms. Hyperopt currently has three algorithms,  random search, Tree of Parzen Estimators (TPE), and adaptive TPE. We are using TPE as the search algorithm.\n",
        "* `max_evals` specifies the maximum number of evaluations.\n",
        "* `trials` stores the information for the evaluations."
      ],
      "metadata": {
        "id": "evxcNNjD-Jl5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMWPQ-UDqXsz",
        "outputId": "f59409c0-a8ed-4cea-b0f3-d17e27a26770"
      },
      "source": [
        "# Optimize\n",
        "best = fmin(fn = objective, space = space, algo = tpe.suggest, max_evals = 48, trials = Trials())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 48/48 [00:11<00:00,  4.23it/s, best loss: -0.9859649122807017]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMk9Ui2O7_5w"
      },
      "source": [
        "After the Bayesian optimization search, we get the best loss of -0.99, meaning that the recall value is about 99%.\n",
        "\n",
        "We can print out the index for the parameters using `print(best)`. To get the values of the best parameters, we can use the `space_eval` and pass in the search space and `best`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOuuBEQeVdf0",
        "outputId": "91400b62-1861-460f-8534-31f7b7677f6b"
      },
      "source": [
        "# Print the index of the best parameters\n",
        "print(best)\n",
        "\n",
        "# Print the values of the best parameters\n",
        "print(space_eval(space, best))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'colsample_bytree': 1, 'gamma': 4, 'learning_rate': 0, 'max_depth': 5, 'reg_alpha': 0, 'reg_lambda': 1}\n",
            "{'colsample_bytree': 0.4, 'gamma': 0.4, 'learning_rate': 0.0001, 'max_depth': 18, 'reg_alpha': 1e-05, 'reg_lambda': 0.01}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyP4ma-89NJz"
      },
      "source": [
        "Next, we apply the best hyperparameters to the `XGBClassifier` and make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU_JLOuUZfel"
      },
      "source": [
        "# Train model using the best parameters\n",
        "xgboost_bo = XGBClassifier(seed=0,\n",
        "                           colsample_bytree=space_eval(space, best)['colsample_bytree'],\n",
        "                           gamma=space_eval(space, best)['gamma'],\n",
        "                           learning_rate=space_eval(space, best)['learning_rate'],\n",
        "                           max_depth=space_eval(space, best)['max_depth'],\n",
        "                           reg_alpha=space_eval(space, best)['reg_alpha'],\n",
        "                           reg_lambda=space_eval(space, best)['reg_lambda']\n",
        "                           ).fit(X_train_transformed,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMToxe5jY5kc",
        "outputId": "413b8db1-da65-4a2f-d874-7286be3880ae"
      },
      "source": [
        "# Make prediction using the best model\n",
        "bayesian_opt_predict = xgboost_bo.predict(X_test_transformed)\n",
        "\n",
        "# Get predicted probabilities\n",
        "bayesian_opt_predict_prob = xgboost_bo.predict_proba(X_test_transformed)[:,1]\n",
        "\n",
        "# Get performance metrics\n",
        "precision, recall, fscore, support = score(y_test, bayesian_opt_predict)\n",
        "\n",
        "# Print result\n",
        "print(f'The recall value for the xgboost Bayesian optimization is {recall[1]:.4f}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The recall value for the xgboost Bayesian optimization is 0.9859\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siPFrrEv-Dz1"
      },
      "source": [
        "The recall value on the test dataset is 98.59%, the same as the random search result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiGJzabJ-MKV"
      },
      "source": [
        "# Summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfIFG8_f-fDI"
      },
      "source": [
        "In this tutorial, we covered how to tune XGBoost hyperparameters using Python. You learned\n",
        "\n",
        "* What are the differences between grid search, random search, and Bayesian optimization?\n",
        "* How to use grid search cross-validation to tune the hyperparameters for the XGBoost model?\n",
        "* How to use random search cross-validation to tune the hyperparameters for the XGBoost model?\n",
        "* How to use Bayesian optimization to tune the hyperparameters for the XGBoost model?\n",
        "* How to compare the results from grid search, random search, and Bayesian optimization?\n",
        "\n",
        "In practice, random search and Bayesian optimization usually have better performance than the grid search because they can tune more parameters on wider ranges of values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-FxiavJMirS"
      },
      "source": [
        "# Recommended Tutorials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENRJflZSMvPb"
      },
      "source": [
        "* [GrabNGoInfo Machine Learning Tutorials Inventory](https://medium.com/grabngoinfo/grabngoinfo-machine-learning-tutorials-inventory-9b9d78ebdd67)\n",
        "- [One-Class SVM For Anomaly Detection](https://medium.com/p/one-class-svm-for-anomaly-detection-6c97fdd6d8af)\n",
        "- [3 Ways for Multiple Time Series Forecasting Using Prophet in Python](https://medium.com/p/3-ways-for-multiple-time-series-forecasting-using-prophet-in-python-7a0709a117f9)\n",
        "- [Four Oversampling And Under-Sampling Methods For Imbalanced Classification Using Python](https://medium.com/p/four-oversampling-and-under-sampling-methods-for-imbalanced-classification-using-python-7304aedf9037)\n",
        "- [Multivariate Time Series Forecasting with Seasonality and Holiday Effect Using Prophet in Python](https://medium.com/p/multivariate-time-series-forecasting-with-seasonality-and-holiday-effect-using-prophet-in-python-d5d4150eeb57)\n",
        "- [How to detect outliers | Data Science Interview Questions and Answers](https://medium.com/p/how-to-detect-outliers-data-science-interview-questions-and-answers-1e400284f6b4)\n",
        "- [Time Series Anomaly Detection Using Prophet in Python](https://medium.com/p/time-series-anomaly-detection-using-prophet-in-python-877d2b7b14b4)\n",
        "- [How to Use R with Google Colab Notebook](https://medium.com/p/how-to-use-r-with-google-colab-notebook-610c3a2f0eab)\n",
        "- [Hyperparameter Tuning For XGBoost](https://medium.com/p/hyperparameter-tuning-for-xgboost-91449869c57e)\n",
        "- [Sentiment Analysis Without Modeling: TextBlob vs. VADER vs. Flair](https://medium.com/p/sentiment-analysis-without-modeling-textblob-vs-vader-vs-flair-657b7af855f4)\n",
        "- [Time Series Anomaly Detection Using Prophet in Python](https://medium.com/grabngoinfo/time-series-anomaly-detection-using-prophet-in-python-877d2b7b14b4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6Xp7sh1cFHp"
      },
      "source": [
        "# References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N-5FR1pcHgv"
      },
      "source": [
        "* [Python sklearn model selection documentation](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)\n",
        "* [Python sklearn GridSearchCV documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
        "* [Python sklearn RandomizedSearchCV documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html)\n",
        "* [Python sklearn StratifiedKFold documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html)\n",
        "* [XGBoost Parameters](https://xgboost.readthedocs.io/en/latest/parameter.html)\n",
        "* [Hyperopt documentation](http://hyperopt.github.io/hyperopt/)\n",
        "* [Hyperopt Github](https://github.com/hyperopt/hyperopt/wiki/FMin)\n",
        "* [max_delta_step in xgboost](https://stats.stackexchange.com/questions/233248/max-delta-step-in-xgboost)"
      ]
    }
  ]
}